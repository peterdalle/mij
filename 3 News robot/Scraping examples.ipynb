{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping examples\n",
    "\n",
    "Some BeautifulSoup examples to help you scrape the HTML from web pages.\n",
    "\n",
    "See [BeautifulSoup documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) for technical reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import all the things!\n",
    "import urllib.request\n",
    "from datetime import *\n",
    "from lxml import html\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define scraping functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scrape all HTML from webpage.\n",
    "def scrapewebpage(url):\n",
    "\t# Open URL and get HTML.\n",
    "\tweb = urllib.request.urlopen(url)\n",
    "\n",
    "\t# Make sure there wasn't any errors opening the URL.\n",
    "\tif (web.getcode() == 200):\n",
    "\t\thtml = web.read()\n",
    "\t\treturn(html)\n",
    "\telse:\n",
    "\t\tprint(\"Error %s reading %s\" % str(web.getcode()), url)\n",
    "\n",
    "# Helper function that scrape the webpage and turn it into soup.\n",
    "def makesoup(url):\n",
    "\thtml = scrapewebpage(url)\n",
    "\treturn(BeautifulSoup(html, \"lxml\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. BeautifulSoup examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A) Find an `id`\n",
    "\n",
    "Use **`find(id=\"name\")`** to find the first HTML tag that has an `id` attribute like this: `<h2 id=\"mp-itn-h2\"></h2>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scrape Wikipedia main page.\n",
    "wp_soup = makesoup(\"https://en.wikipedia.org/wiki/Main_Page\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Match the <h2> tag with id the id mp-itn-h2\n",
    "h2 = wp_soup.find(id=\"mp-itn-h2\")\n",
    "\n",
    "h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Only get the text inside <h2>.\n",
    "h2.get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B) Find a `class`\n",
    "\n",
    "Use **`find(\"\", \"name\")`** to find the first HTML tag that has a `class` attribute like this: `<h2 class=\"name\"></h2>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scrape Wikipedia main page.\n",
    "wp_soup = makesoup(\"https://en.wikipedia.org/wiki/Main_Page\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find the first HTML tag that has class mw-headline.\n",
    "headline = wp_soup.find(\"\", \"mw-headline\")\n",
    "\n",
    "headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Only get the text inside the <span>.\n",
    "headline.get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C) Find everything with a `class`\n",
    "\n",
    "Use **`find_all(\"\", \"name\")`** to find all HTML tags that has a `class` attribute like this: `<h2 class=\"name\"></h2>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scrape Wikipedia main page.\n",
    "wp_soup = makesoup(\"https://en.wikipedia.org/wiki/Main_Page\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find all HTML tag that has class mw-headline.\n",
    "all_headlines = wp_soup.find_all(\"\", \"mw-headline\")\n",
    "\n",
    "all_headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now we have a list that we can use a for loop.\n",
    "for headline in all_headlines:\n",
    "    headline = headline.get_text()\n",
    "    print(headline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D) Find all `<h3>`\n",
    "\n",
    "Use **`find_all(\"h3\")`** to get all `<h3>` (or something else)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scrape Wikipedia main page.\n",
    "wp_soup = makesoup(\"https://en.wikipedia.org/wiki/Main_Page\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find all HTML tag that has class mw-headline.\n",
    "all_h3 = wp_soup.find_all(\"h3\")\n",
    "\n",
    "all_h3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now we have a list that we can use a for loop.\n",
    "for h3 in all_h3:\n",
    "    h3 = h3.get_text()\n",
    "    print(h3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E) Find all column values in a table\n",
    "\n",
    "Use for to loop through a `<table>` and extract all column values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scrape a Wikipedia page with a table.\n",
    "champ_soup = makesoup(\"https://en.wikipedia.org/wiki/European_Road_Championships\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find <table class=\"wikitable\">.\n",
    "table = champ_soup.find(\"table\", \"wikitable\")\n",
    "\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Go through each row and take the text from 1st and 2nd column.\n",
    "rows = table.find_all('tr')\n",
    "for row in rows:\n",
    "    cols = row.find_all('td')\n",
    "    if len(cols) > 0:\n",
    "        Year = cols[0].get_text()        # Get the text in the 1st column.\n",
    "        Country = cols[1].get_text()     # Get the text in the 2nd column.\n",
    "\n",
    "        print(Year + \" \" + Country)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F) Find a specific cell value in a table\n",
    "\n",
    "Use this if you know the row and column of the `<table>` of the information you want to extract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table = champ_soup.find(\"table\", \"wikitable\")\n",
    "\n",
    "# Get cell value from row 5, column 1.\n",
    "cell = table.find_all('tr')[5].find_all('td')[1].get_text()\n",
    "\n",
    "cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G) Find nested things\n",
    "\n",
    "Use this if you want to find things that are nested inside each oher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Scrape Wikipedia main page.\n",
    "wp_soup = makesoup(\"https://en.wikipedia.org/wiki/Main_Page\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find <table class=\"mp-middle\">.\n",
    "middle_table = wp_soup.find(\"table\", id=\"mp-middle\")\n",
    "\n",
    "# In the <table>, find <h2>.\n",
    "h2 = middle_table.find(\"h2\")\n",
    "\n",
    "h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Only get the text inside the <h2>.\n",
    "h2.get_text()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
