{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape court rulings from InfoCuria\n",
    "\n",
    "The goal is to scrape the most recent judgments and opinions from [InfoCuria - Case-law of the Court of Justice](https://curia.europa.eu/).\n",
    "\n",
    "The scraping is done in two steps:\n",
    "\n",
    "1. **Scrape recent rulings**. Get the [most recent judgments and opinions](http://curia.europa.eu/juris/documents.jsf?language=en&jur=C&cit=none%252CC%252CCJ%252CR%252C2008E%252C%252C%252C%252C%252C%252C%252C%252C%252C%252Ctrue%252Cfalse%252Cfalse&td=%24mode%3D8D%24from%3D2018.2.1%24to%3D2018.2.8%3B%3B%3BPUB1%2CPUB3%3BNPUB1%3B%3BORDALL&ordreTri=dateDesc&pcs=O&redirection=doc&page=1) from the table with search results. Store the link of each ruling in a link list.\n",
    "2. **Scrape each ruling**. Get each individual page ([see example](http://curia.europa.eu/juris/document/document.jsf?text=&docid=199202&pageIndex=0&doclang=EN&mode=req&dir=&occ=first&part=1&cid=768868)) by going to each individual link in the link list.\n",
    "\n",
    "\n",
    "After that, the text of the ruling decisions are saved into a single file that can be used for later analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions\n",
    "\n",
    "Here we'll define the scraping functions that we've used many times already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries that we need for the web scraping.\n",
    "import urllib.request\n",
    "from lxml import html\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Scrape all HTML from webpage.\n",
    "def scrapewebpage(url):\n",
    "\t# Open URL and get HTML.\n",
    "\tweb = urllib.request.urlopen(url)\n",
    "\n",
    "\t# Make sure there wasn't any errors opening the URL.\n",
    "\tif (web.getcode() == 200):\n",
    "\t\thtml = web.read()\n",
    "\t\treturn(html)\n",
    "\telse:\n",
    "\t\tprint(\"Error %s reading %s\" % str(web.getcode()), url)\n",
    "\n",
    "# Helper function that scrape the webpage and turn it into soup.\n",
    "def makesoup(url):\n",
    "\thtml = scrapewebpage(url)\n",
    "\treturn(BeautifulSoup(html, \"lxml\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1. Scrape recent\n",
    "\n",
    "Get the [most recent judgments and opinions](http://curia.europa.eu/juris/documents.jsf?language=en&jur=C&cit=none%252CC%252CCJ%252CR%252C2008E%252C%252C%252C%252C%252C%252C%252C%252C%252C%252Ctrue%252Cfalse%252Cfalse&td=%24mode%3D8D%24from%3D2018.2.1%24to%3D2018.2.8%3B%3B%3BPUB1%2CPUB3%3BNPUB1%3B%3BORDALL&ordreTri=dateDesc&pcs=O&redirection=doc&page=1) from the table with search results. The table can be found by looking at the table with search results and this table is named `<table class=\"detail_table_documents\">`. In this table, there are many columns but we're only interested in the column \"Name of the parties\" and the links to the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape the page with most recent judgments and opinions.\n",
    "judgments_page = makesoup(\"http://curia.europa.eu/juris/documents.jsf?language=en&jur=C&cit=none%252CC%252CCJ%252CR%252C2008E%252C%252C%252C%252C%252C%252C%252C%252C%252C%252Ctrue%252Cfalse%252Cfalse&td=%24mode%3D8D%24from%3D2018.2.1%24to%3D2018.2.8%3B%3B%3BPUB1%2CPUB3%3BNPUB1%3B%3BORDALL&ordreTri=dateDesc&pcs=O&redirection=doc&page=1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the table from the page.\n",
    "table = judgments_page.find(\"table\", \"detail_table_documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Commission v Spain\n",
      " Lloyd's of London\n",
      " Commission v Greece\n",
      " Commission v Germany\n",
      " EV\n",
      " Pfizer Ireland Pharmaceuticals, Operations Support Group\n",
      " American Express\n",
      " American Express\n",
      " Lada\n",
      " Altun and Others\n",
      " Louboutin and Christian Louboutin\n",
      " Kompania Piwowarska\n",
      " Jehovan todistajat\n",
      " Industrias Químicas del Vallés\n",
      " Panalpina World Transport (Holding) and Others v Commission\n",
      " Deutsche Bahn and Others v Commission\n",
      " Schenker v Commission\n",
      " Kühne + Nagel International and Others v Commission\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list to store the links.\n",
    "links = []\n",
    "\n",
    "# Go through row by row in the table. Note that tr is a row, td is a column.\n",
    "for row in table.find_all(\"tr\"):\n",
    "    name = row.find(\"td\", \"table_cell_nom_usuel\") # Find the first column (td) with the class name \"table_cell_nom_usuel\".\n",
    "    link = row.find(\"td\", \"table_cell_links_eurlex\") # Find the first column (td) with the class name \"table_cell_links_eurlex\".\n",
    "    if name:\n",
    "        # Print the name of the parties in the ruling.\n",
    "        print(name.get_text())\n",
    "    if link:\n",
    "        links.append(link.find(\"a\")[\"href\"]) # Find <a href=\"link\"> and add link to list.\n",
    "        #print(link.find(\"a\")[\"href\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many links did we get?\n",
    "len(links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2. Scrape each ruling\n",
    "\n",
    "Each individual page ([see example](http://curia.europa.eu/juris/document/document.jsf?text=&docid=199202&pageIndex=0&doclang=EN&mode=req&dir=&occ=first&part=1&cid=768868)) only consists of text, and this is much easier to scrape compared to the previous step. We only need to find `<div id=\"document_content\">` which contains the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping http://curia.europa.eu/juris/document/document.jsf;jsessionid=9ea7d2dc30dd37d6ecd89c8d44b08a09a01d3ae6dd96.e34KaxiLc3qMb40Rch0SaxyNaNn0?text=&docid=199206&pageIndex=0&doclang=ES&mode=req&dir=&occ=first&part=1&cid=789789\n",
      "Scraping http://curia.europa.eu/juris/document/document.jsf;jsessionid=9ea7d2dc30dd37d6ecd89c8d44b08a09a01d3ae6dd96.e34KaxiLc3qMb40Rch0SaxyNaNn0?text=&docid=199201&pageIndex=0&doclang=en&mode=req&dir=&occ=first&part=1&cid=789789\n",
      "Scraping http://curia.europa.eu/juris/document/document.jsf;jsessionid=9ea7d2dc30dd37d6ecd89c8d44b08a09a01d3ae6dd96.e34KaxiLc3qMb40Rch0SaxyNaNn0?text=&docid=199202&pageIndex=0&doclang=en&mode=req&dir=&occ=first&part=1&cid=789789\n",
      "Scraping http://curia.europa.eu/juris/document/document.jsf;jsessionid=9ea7d2dc30dd37d6ecd89c8d44b08a09a01d3ae6dd96.e34KaxiLc3qMb40Rch0SaxyNaNn0?text=&docid=199207&pageIndex=0&doclang=DE&mode=req&dir=&occ=first&part=1&cid=789789\n",
      "Scraping http://curia.europa.eu/juris/document/document.jsf;jsessionid=9ea7d2dc30dd37d6ecd89c8d44b08a09a01d3ae6dd96.e34KaxiLc3qMb40Rch0SaxyNaNn0?text=&docid=199190&pageIndex=0&doclang=BG&mode=req&dir=&occ=first&part=1&cid=789789\n",
      "Scraping http://curia.europa.eu/juris/document/document.jsf;jsessionid=9ea7d2dc30dd37d6ecd89c8d44b08a09a01d3ae6dd96.e34KaxiLc3qMb40Rch0SaxyNaNn0?text=&docid=199189&pageIndex=0&doclang=en&mode=req&dir=&occ=first&part=1&cid=789789\n",
      "Scraping http://curia.europa.eu/juris/document/document.jsf;jsessionid=9ea7d2dc30dd37d6ecd89c8d44b08a09a01d3ae6dd96.e34KaxiLc3qMb40Rch0SaxyNaNn0?text=&docid=199182&pageIndex=0&doclang=en&mode=req&dir=&occ=first&part=1&cid=789789\n",
      "Scraping http://curia.europa.eu/juris/document/document.jsf;jsessionid=9ea7d2dc30dd37d6ecd89c8d44b08a09a01d3ae6dd96.e34KaxiLc3qMb40Rch0SaxyNaNn0?text=&docid=199181&pageIndex=0&doclang=en&mode=req&dir=&occ=first&part=1&cid=789789\n",
      "Scraping http://curia.europa.eu/juris/document/document.jsf;jsessionid=9ea7d2dc30dd37d6ecd89c8d44b08a09a01d3ae6dd96.e34KaxiLc3qMb40Rch0SaxyNaNn0?text=&docid=199101&pageIndex=0&doclang=en&mode=req&dir=&occ=first&part=1&cid=789789\n",
      "Scraping http://curia.europa.eu/juris/document/document.jsf;jsessionid=9ea7d2dc30dd37d6ecd89c8d44b08a09a01d3ae6dd96.e34KaxiLc3qMb40Rch0SaxyNaNn0?text=&docid=199097&pageIndex=0&doclang=en&mode=req&dir=&occ=first&part=1&cid=789789\n",
      "Scraping http://curia.europa.eu/juris/document/document.jsf;jsessionid=9ea7d2dc30dd37d6ecd89c8d44b08a09a01d3ae6dd96.e34KaxiLc3qMb40Rch0SaxyNaNn0?text=&docid=199102&pageIndex=0&doclang=en&mode=req&dir=&occ=first&part=1&cid=789789\n",
      "Scraping http://curia.europa.eu/juris/document/document.jsf;jsessionid=9ea7d2dc30dd37d6ecd89c8d44b08a09a01d3ae6dd96.e34KaxiLc3qMb40Rch0SaxyNaNn0?text=&docid=198950&pageIndex=0&doclang=BG&mode=req&dir=&occ=first&part=1&cid=789789\n",
      "Scraping http://curia.europa.eu/juris/document/document.jsf;jsessionid=9ea7d2dc30dd37d6ecd89c8d44b08a09a01d3ae6dd96.e34KaxiLc3qMb40Rch0SaxyNaNn0?text=&docid=198949&pageIndex=0&doclang=en&mode=req&dir=&occ=first&part=1&cid=789789\n",
      "Scraping http://curia.europa.eu/juris/document/document.jsf;jsessionid=9ea7d2dc30dd37d6ecd89c8d44b08a09a01d3ae6dd96.e34KaxiLc3qMb40Rch0SaxyNaNn0?text=&docid=198948&pageIndex=0&doclang=BG&mode=req&dir=&occ=first&part=1&cid=789789\n",
      "Scraping http://curia.europa.eu/juris/document/document.jsf;jsessionid=9ea7d2dc30dd37d6ecd89c8d44b08a09a01d3ae6dd96.e34KaxiLc3qMb40Rch0SaxyNaNn0?text=&docid=198944&pageIndex=0&doclang=en&mode=req&dir=&occ=first&part=1&cid=789789\n",
      "Scraping http://curia.europa.eu/juris/document/document.jsf;jsessionid=9ea7d2dc30dd37d6ecd89c8d44b08a09a01d3ae6dd96.e34KaxiLc3qMb40Rch0SaxyNaNn0?text=&docid=198946&pageIndex=0&doclang=en&mode=req&dir=&occ=first&part=1&cid=789789\n",
      "Scraping http://curia.europa.eu/juris/document/document.jsf;jsessionid=9ea7d2dc30dd37d6ecd89c8d44b08a09a01d3ae6dd96.e34KaxiLc3qMb40Rch0SaxyNaNn0?text=&docid=198947&pageIndex=0&doclang=en&mode=req&dir=&occ=first&part=1&cid=789789\n",
      "Scraping http://curia.europa.eu/juris/document/document.jsf;jsessionid=9ea7d2dc30dd37d6ecd89c8d44b08a09a01d3ae6dd96.e34KaxiLc3qMb40Rch0SaxyNaNn0?text=&docid=198945&pageIndex=0&doclang=DE&mode=req&dir=&occ=first&part=1&cid=789789\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Import time to be able to delay the scraping.\n",
    "import time\n",
    "\n",
    "# Create an empty list to store the texts.\n",
    "text_list = []\n",
    "\n",
    "# Scrape all the links in the list.\n",
    "for link in links:\n",
    "    print(\"Scraping \" + link) \n",
    "    page = makesoup(link)    # Scrape each individual page in the list.\n",
    "    text = page.find(\"\", id=\"document_content\").get_text() # Find <div id=\"document_content\">\n",
    "    text_list.append(text)   # Add text to list.\n",
    "    time.sleep(1.0)          # Delay 1.0 second.\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many texts did we get?\n",
    "# It should be the same as the number of links, otherwise something is probably wrong.\n",
    "len(text_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to file\n",
    "\n",
    "Let's save all the texts to a single file named `all_texts.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved!\n"
     ]
    }
   ],
   "source": [
    "# All texts are kept separate in the list text_list.\n",
    "# This will join all texts together into one big text separated by a new line (\\n).\n",
    "one_big_text = \"\\n\".join(text_list)\n",
    "\n",
    "# Save the text to a single file.\n",
    "file = open(\"all_texts.txt\", \"w\", encoding=\"utf-8\")\n",
    "file.writelines(one_big_text)\n",
    "file.close()\n",
    "print(\"File saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
